{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Major_Code_without_data_Refining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6isbcTJSmC6"
      },
      "source": [
        "#!unzip \"/content/drive/MyDrive/Pneumonia_dataset/archive.zip\" -d \"/content/drive/MyDrive/Major_project_code/MajorCode/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzw3wdZlaLiJ"
      },
      "source": [
        "import numpy as np                     \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2 as cv\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVy-EBcPaLkj"
      },
      "source": [
        "path1 = '/content/drive/MyDrive/Major_project_code/MajorCode/chest_xray/test/'\n",
        "train = os.listdir(path1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXFWcPyDaLm_",
        "outputId": "8ce4197e-6603-4142-836a-2b6bd31e10ed"
      },
      "source": [
        "folders=[]\n",
        "folders = [f for f in sorted(os.listdir(path1))]\n",
        "print(folders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NORMAL', 'PNEUMONIA']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7k2MMXOaLoV",
        "outputId": "b0ea5dd5-f7cb-4bf9-af38-9f6f061cab79"
      },
      "source": [
        "labels = folders\n",
        "print (f'The labels are {labels}')\n",
        " \n",
        "# setting the size of images that we want\n",
        " \n",
        "image_size = 224\n",
        "print(f'All images to be resized into {image_size}*{image_size} pixels')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The labels are ['NORMAL', 'PNEUMONIA']\n",
            "All images to be resized into 224*224 pixels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhWZO_NNaLqo"
      },
      "source": [
        "i = []\n",
        "\n",
        "while(True):\n",
        "\n",
        "    i.append('a')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrVYg0fjaLsr"
      },
      "source": [
        "# defining a function to load images and labels together\n",
        "# this function will also resize the images\n",
        " \n",
        "def load_train5(path1):\n",
        "    \n",
        "    images = []\n",
        "    \n",
        "    for label in labels:\n",
        "        direc = os.path.join(path1, label)\n",
        "        class_num = labels.index(label)\n",
        "        \n",
        "        for image in os.listdir(direc):\n",
        "            image_read = cv.imread(os.path.join(direc,image))\n",
        "            image_resized = cv.resize(image_read,(image_size,image_size),3)#modified here for getting output as (1,224,224,3) not as (224,224)\n",
        "            images.append([image_resized,class_num])\n",
        "            \n",
        "    return np.array(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZBWB-LEaLu4",
        "outputId": "aef3aaf4-b875-4c8a-a10f-95c1a0473529"
      },
      "source": [
        "#loading without Grayscale \n",
        "train_images5 = load_train5(path1)\n",
        " \n",
        "print(f'Shape of the training images = {train_images5.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the training images = (624, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6nqmpp2aLxM",
        "outputId": "c1a6042a-8108-4a15-a230-0e5452435867"
      },
      "source": [
        "train_images5.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(624, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVbdVDoTaLzT",
        "outputId": "7647e8db-5f93-482f-dc4c-2592bf24d5cb"
      },
      "source": [
        "#loading the images and labels seperately in X and y, to be used later for training\n",
        "X5 = []\n",
        "y5 = []\n",
        "\n",
        "for feature, label in train_images5:\n",
        "    X5.append(feature)\n",
        "    y5.append(label)\n",
        "    \n",
        "print (f'Length of X = {len(X5)}')\n",
        "print (f'Length of y = {len(y5)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of X = 624\n",
            "Length of y = 624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWbeN5bOaL1c"
      },
      "source": [
        "X51=np.array(X5)\n",
        "y51= np.array(y5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUCrHa0qaL3T"
      },
      "source": [
        "with open('testpneumoniaandlabels.npy', 'wb') as f:\n",
        "    np.save(f, X51)\n",
        "    np.save(f, y51)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAD-ud0haL5T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmkx2cbaaL7G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzJF4PmsaL9R"
      },
      "source": [
        "path2 = '/content/drive/MyDrive/Major_project_code/MajorCode/chest_xray/train/'\n",
        "train = os.listdir(path2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyapYOfGaL_-",
        "outputId": "08fb1bd8-9b6e-4bbd-a475-64c40fc2e9bd"
      },
      "source": [
        "folders1=[]\n",
        "folders1 = [f for f in sorted(os.listdir(path2))]\n",
        "print(folders1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NORMAL', 'PNEUMONIA']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y5MmfrKa2r5",
        "outputId": "7c2d81ee-d0a2-4994-acf2-34d4d70c424c"
      },
      "source": [
        "labels1 = folders1\n",
        "print (f'The labels are {labels1}')\n",
        " \n",
        "# setting the size of images that we want\n",
        " \n",
        "image_size = 224\n",
        "print(f'All images to be resized into {image_size}*{image_size} pixels')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The labels are ['NORMAL', 'PNEUMONIA']\n",
            "All images to be resized into 224*224 pixels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCAhri1ha2ue"
      },
      "source": [
        "# defining a function to load images and labels together\n",
        "# this function will also resize the images\n",
        " \n",
        "def load_train6(path2):\n",
        "    \n",
        "    images1 = []\n",
        "    \n",
        "    for label in labels1:\n",
        "        direc1 = os.path.join(path2, label)\n",
        "        class_num = labels.index(label)\n",
        "        \n",
        "        for image in os.listdir(direc1):\n",
        "            image_read = cv.imread(os.path.join(direc1,image))\n",
        "            image_resized = cv.resize(image_read,(image_size,image_size),3)#modified here for getting output as (1,224,224,3) not as (224,224)\n",
        "            images1.append([image_resized,class_num])\n",
        "            \n",
        "    return np.array(images1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0r-GQZTa2wl",
        "outputId": "03d08731-7f9f-4eaf-91ed-3b8b24317070"
      },
      "source": [
        "#loading without Grayscale \n",
        "train_images6 = load_train6(path2)\n",
        " \n",
        "print(f'Shape of the training images = {train_images6.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the training images = (5216, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2vQkgU_a217",
        "outputId": "a2ddf416-c1d7-4b03-bec9-0dacadb17792"
      },
      "source": [
        "#loading the images and labels seperately in X and y, to be used later for training\n",
        "X4 = []\n",
        "y4 = []\n",
        "\n",
        "for feature, label in train_images6:\n",
        "    X4.append(feature)\n",
        "    y4.append(label)\n",
        "    \n",
        "print (f'Length of X = {len(X4)}')\n",
        "print (f'Length of y = {len(y4)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of X = 5216\n",
            "Length of y = 5216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dE7Latja24w"
      },
      "source": [
        "X41=np.array(X4)\n",
        "y41= np.array(y4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhH-tw3oa27c"
      },
      "source": [
        "with open('trainpneumoniaandlabels.npy', 'wb') as f:\n",
        "    np.save(f, X41)\n",
        "    np.save(f, y41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j3Neuy3a29I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyBgwVkBDTLB"
      },
      "source": [
        "Transfer Learning part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pZ5rOjva2_Y"
      },
      "source": [
        "with open('/content/drive/MyDrive/Major_project_code/Array_of_test_and_train/trainpneumoniaandlabels.npy', 'rb') as f:\n",
        "    X41 = np.load(f)\n",
        "    y41 = np.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLTosM9La3Bx"
      },
      "source": [
        "with open('/content/drive/MyDrive/Major_project_code/Array_of_test_and_train/testpneumoniaandlabels.npy', 'rb') as f:\n",
        "    X51 = np.load(f)\n",
        "    y51 = np.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaaK1scsa3D4"
      },
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "import os\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Major_project_code/MajorCode/chest_xray/train'\n",
        "valid_path = '/content/drive/MyDrive/Major_project_code/MajorCode/chest_xray/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6UcI7W4a3Fq"
      },
      "source": [
        "import tensorflow as tf\n",
        "vgg1 = tf.keras.applications.DenseNet121(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgAx9D2asyqp"
      },
      "source": [
        "for layer in vgg1.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDCgIVossytM"
      },
      "source": [
        "folders = glob('/content/drive/MyDrive/Major_project_code/MajorCode/chest_xray/train/*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGsJZZ0zsyvh"
      },
      "source": [
        "x = Flatten()(vgg1.output)\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "prediction = Dense(len(folders), activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mSmGu7Nsyxn"
      },
      "source": [
        "modeled = Model(inputs=vgg1.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQstEsNVsyzK"
      },
      "source": [
        "modeled.compile(\n",
        "  loss='categorical_crossentropy',\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i81b5UVsy1b"
      },
      "source": [
        "import tensorflow as tf\n",
        "training_labels=tf.keras.utils.to_categorical(y41)\n",
        "testing_labels1=tf.keras.utils.to_categorical(y51)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAg98QOY5x8G"
      },
      "source": [
        "modeled.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQG6j0lmaMBY"
      },
      "source": [
        "m2=modeled.fit(X41,training_labels,epochs=50,validation_data=(X51,testing_labels1))#vgg19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9usp_2e4wWq",
        "outputId": "f3b7a3e1-7a9b-49d2-e756-d60e1d11aad4"
      },
      "source": [
        "m2=modeled.fit(X41,training_labels,epochs=10,validation_data=(X51,testing_labels1))#Resnet50"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 1.3187e-06 - accuracy: 1.0000 - val_loss: 3.5552 - val_accuracy: 0.7917\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 1.2295e-06 - accuracy: 1.0000 - val_loss: 3.5355 - val_accuracy: 0.7917\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 1.1564e-06 - accuracy: 1.0000 - val_loss: 3.5803 - val_accuracy: 0.7917\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 20s 123ms/step - loss: 1.0611e-06 - accuracy: 1.0000 - val_loss: 3.5356 - val_accuracy: 0.7917\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 1.0063e-06 - accuracy: 1.0000 - val_loss: 3.5540 - val_accuracy: 0.7917\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 9.3213e-07 - accuracy: 1.0000 - val_loss: 3.5903 - val_accuracy: 0.7917\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 8.7655e-07 - accuracy: 1.0000 - val_loss: 3.6207 - val_accuracy: 0.7917\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 8.1373e-07 - accuracy: 1.0000 - val_loss: 3.5933 - val_accuracy: 0.7917\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 7.5863e-07 - accuracy: 1.0000 - val_loss: 3.5690 - val_accuracy: 0.7917\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 20s 124ms/step - loss: 7.0840e-07 - accuracy: 1.0000 - val_loss: 3.6048 - val_accuracy: 0.7917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "j86VixNj9sdo",
        "outputId": "22a67473-78e6-496c-ebc8-aa8183910c57"
      },
      "source": [
        "plt.plot(m2.history['accuracy'], label='accuracy')#Resnet50\n",
        "plt.plot(m2.history['val_accuracy'], label='val_accuracy')\n",
        "plt.plot(m2.history['loss'], label='loss')\n",
        "plt.plot(m2.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpgHlKWy92mq",
        "outputId": "2d8dbaff-3b70-41bf-b00a-96e6de289e68"
      },
      "source": [
        "pred2=modeled.predict(X51)#Resnet50\n",
        "predicted_classes1 = np.argmax(pred2, axis=1)\n",
        "predicted_classes1\n",
        "\n",
        "predicted_labels1=tf.keras.utils.to_categorical(predicted_classes1)\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "confusion_matrix(predicted_classes1, y51)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[105,   1],\n",
              "       [129, 389]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWOn1nj-Bb-",
        "outputId": "60d04414-ba0e-472a-fe65-90ab6dc0b026"
      },
      "source": [
        "import sklearn#Resnet50\n",
        "p1=sklearn.metrics.classification_report(y51,predicted_classes1)\n",
        "print(p1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.45      0.62       234\n",
            "           1       0.75      1.00      0.86       390\n",
            "\n",
            "    accuracy                           0.79       624\n",
            "   macro avg       0.87      0.72      0.74       624\n",
            "weighted avg       0.84      0.79      0.77       624\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tye6YGkTDNlz"
      },
      "source": [
        "My algo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnYKVEbRDAtf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRzhsIrKDjWR"
      },
      "source": [
        "with open('/content/drive/MyDrive/Major_project_code/Array_of_test_and_train/trainpneumoniaandlabels.npy', 'rb') as f:\n",
        "    X41 = np.load(f)\n",
        "    y41 = np.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjeZMmpKDjS-"
      },
      "source": [
        "with open('/content/drive/MyDrive/Major_project_code/Array_of_test_and_train/testpneumoniaandlabels.npy', 'rb') as f:\n",
        "    X51 = np.load(f)\n",
        "    y51 = np.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImYyjH0fDu-m"
      },
      "source": [
        "If needed weights balancing then use it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AMIFsc8DjP2"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        " \n",
        "class_weights = class_weight.compute_class_weight(\n",
        "               'balanced',\n",
        "                np.unique(training_set.classes), \n",
        "                training_set.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmpwOC6QDjMY"
      },
      "source": [
        "class_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYMK8dt0DjKW"
      },
      "source": [
        "class_weighted={0: 6.86138614, 1: 0.68852459, 2: 0.7133299}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO30OHPdEWBu"
      },
      "source": [
        "Needed weights code ended here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iwf8iZMEV36"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTAQVgVfDjH6"
      },
      "source": [
        "import tensorflow as tf\n",
        "training_labels=tf.keras.utils.to_categorical(y41)\n",
        "testing_labels1=tf.keras.utils.to_categorical(y51)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRJHoVuhDjGC"
      },
      "source": [
        "# baseline model with data augmentation on the X-Ray dataset\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten,Dropout\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "import tensorflow as tf\n",
        "import keras.backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTNwGCohDjDn"
      },
      "source": [
        "def precision(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "def recall(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224,224, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "# compile model\n",
        "opt =  Adam()\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', precision, recall])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZieKlXdhDjCE"
      },
      "source": [
        "#without smoting, but with metrics=['precision','recall']\n",
        "#@tf.function got this without augmentation just by scratch code with class_weights\n",
        "\"\"\"m2=model.fit(X41,training_labels,epochs=30,validation_data=(X51,testing_labels1),class_weight=class_weighted)\"\"\"#working after making y41 to (training_labels=tf.keras.utils.to_categorical(y41))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyvNLjeYZIKu",
        "outputId": "9bdd1ab0-a535-46f3-d97e-21fab6377212"
      },
      "source": [
        "training_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5216, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uncFo4VVDi_L"
      },
      "source": [
        "m2=model.fit(X41,training_labels,epochs=30,validation_data=(X51,testing_labels1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53DBOgegDi9f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WltCEzXiWHK3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LEG1Ip5Eeo9"
      },
      "source": [
        "My algo ended here"
      ]
    }
  ]
}